%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Design and Analysis}

\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi


\section{Preliminaries}

\subsection{CountMin Sketch}

\subsection{gSketch}

\subsection{gMatrix}

\section{Partitioning Scheme}

We implement the idea of partitioning from \cite{DBLP} onto the gMatrix.

A data sample is needed to perform the partitioning. In the experiment, we perform reservoir sampling on the original dataset to obtain the data sample. The size of the data sample is 5\% of the original size of the dataset.

The gMatrix is divided into partitions. Each partition is associated with a set of source vertices. Each source vertex is then only associated with exactly one partition. Edge $(u,v)$ is stored in one of the partitions if and only if $u$ is in the set of source vertices associated with the partition. The idea of the partitioning is to group edges with similar frequencies in the same partition to improve sketch accuracy.

The statistical variances of the frequencies of edges (from the data sample) with common source vertex are computed. We select source vertices which have variances not exceeding a certain threshold (variance of 100 is used in the experiment). An outlier partition is reserved to store frequencies of edges in the dataset whose source vertex is either not found in the data sample or are not suitable for the purpose of the partitioning, i.e. the statistical variance of the frequencies of all edges with the same source vertex in the data sample is exceeding the threshold.

Determining the right outlier partition size is very critical for the effectiveness of the partitioning, even more so than in partitioning the gSketch\cite{DBLP}. We determine the outlier partition size ratio by estimating the outlier ratio from the data sample. We do so by first splitting the data sample into two; the first consists of 90\% of the whole data sample, and the other split consists of the rest; then, after selecting the suitable source vertices from the first split, the ratio of outliers in the second split is computed, which is essentially the ratio of the number of source vertices in the split not found among the previously-selected source vertices, to the size of the split. Then, it is assigned as the outlier partition size ratio.

The partitioning algorithm is no different than in \cite{DBLP}. 

\begin{algorithm}
\caption{Sketch-Partitioning (Data Sample: $D$)}\label{euclid}
\begin{algorithmic}[1]

\State Create a root node $S$ of the partitioning tree as an
active node;
\State $S.sides \gets h$;
\State $S.depth \gets d$;
\State Create an empty list $L$ containing $S$ only;
\While{$L \neq \varnothing$ }
\State Partition active node $S \in L$ based on D into $S_1$, $S_2$ by minimizing overall relative error;
\State $S_1.rows = S_2.rows = \frac{S.rows}{2};$
\State $L \gets L \setminus \left \{ S \right \};$
\For{$i \in \left[ 1..2 \right]$}
    \If{$(S_i.sides >= w_0)$ and ($\sum_{v \in V_S} \tilde{d}(v) \leqslant C \cdot S_i.sides$)}
    
    \State $L \gets L \cup S_i$;
    \Else
    \State Construct the localized sketch $S_i$;
    
    \EndIf
\EndFor
\EndWhile

\end{algorithmic}
\end{algorithm}

The suitable source vertices are sorted based on non-decreasing average frequency of edges emanating from them $f_v/d_v$ in the data sample, where $f_v$ is the sum of frequencies of all edges in the data sample with source vertex $v$, and $d_v$ is the out-degree of vertex $v$. The sorted source vertex set is then recursively split into two, and each split minimizes the overall relative error E. \[E = \sum_{v \in S_1} \frac{d_v \cdot F_{S_1}}{f_v / d_v} + \sum_{v \in S_2} \frac{d_v \cdot F_{S_1}}{f_v / d_v}\]

The recursion stops when either the size of the partition becomes small enough, i.e. the number of rows is less than a user-specified threshold $r_0$ (which is fixed at 100 in this experiment), or when the probability of collision in any particular cell in the sketch can be bounded above by a user-speficied threshold $C$, which is the case when the density of distinct edges, $\sum_{v \in s} d_v/(S.rows \cdot S.cols)$, is also bounded above by $C$, as proven in \cite{DBLP}.


\section{Edge Frequency Queries}

\subsubsection{Description}
Since there is only one partition associated with each source vertex, to retrieve the estimated frequency for an arbitrary edge $(i,j)$:

\begin{enumerate}
  \item Find partition $p$ that is responsible for $i$
  \item Find the minimum of $V_P(g_k(i),g_k(j),k)$ for all $k \in \{1..w\}$, where $V_P$ is the value of the cell in the partition $p$. 
\end{enumerate}

\subsubsection{Analysis}

Since obtaining the frequency estimate of an arbitrary edge only depends on the partition containing the edge, we observe how each partition answers the query.

Let $S$ be a gMatrix of size $h\times h\times w$. Suppose the partitioning step is performed already. Note that any of the produced partitions will have number of rows equal to $\frac{h}{2^d}$ where $d$ is the depth of the recursion in which the partition is built. Let $p$ be an arbitrary partition. The size of $p$ is $\frac{h}{2^d}\times h\times w$.

\begin{theorem}
\label{efreqguarantee}
Let $(i,j)$ be an edge in $p$, $Q(i,j)$ be its actual frequency, and $\overline{Q(i,j)}$ be its estimated frequency according to partition $p$. Let $L_p$ be the total frequency of edges received so far in the arbitrary partition, i.e. total frequency of edges $(u,v)$ such that $u$ is associated with $p$. Let $A_p(j)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $v=j$. Let $B_p(i)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $u=i$. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
  
  \[
P(Q(i,j) \leq \overline{Q(i,j)} \leq Q(i,j) + L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon) \geq 1-(\frac{2^{d+1}+1}{h^2\cdot\epsilon})^w
\]

\end{theorem}

\begin{proof}
  Note that $\overline{Q(i,j)}$ is essentially $Q(i,j)$ added with the frequencies of spurious edges mapped into the same cell $(g_k(i),g_k(j),k)$ in the partition, so $P(Q(i,j) \leq \overline{Q(i,j)}) = 1$. We remain to show that

\[
P(\overline{Q(i,j)} \leq Q(i,j) + L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon) \geq 1-(\frac{2^{d+1}+1}{h^2\cdot\epsilon})^w
\]

  There are three possible cases for the spurious edges.
  
The first possible case of spurious edges $(u,v)$ are those for which $u \neq i$ and $v \neq j$. Any of such edges are equally likely to be mapped into any cell in $p$, and the probability to be mapped into any particular cell is $\frac{1}{h \cdot \frac{h}{2^d}} = \frac{2^d}{h^2}$. Let $X_k$ be a random variable that represents the number of such spurious edges that are mapped into $(g_k(i),g_k(j),k)$. Therefore, $E[X_k] = \frac{2^dL_p}{h^2}$. Then, by Markov's inequality,

\begin{equation} \label{efreq1}
P(X_k \geq L_p \cdot \epsilon) \leq \frac{E[X_k]}{L_p \cdot \epsilon} = \frac{2^d}{h^2\epsilon}
\end{equation}

The second possible case of spurious edges $(u,v)$ are those for which $u \neq i$ but $v=j$. The probability that any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{\frac{h}{2^d}} = \frac{2^d}{h}$. Let $Y_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Y_k] = \frac{2^dA_p(j)}{h}$. By Markov's inequality,

\begin{equation} \label{efreq2}
P(Y_k \geq h A_p(j) \cdot \epsilon) \leq \frac{E[Y_k]}{h A_p(j) \cdot \epsilon} = \frac{2^d}{h^2\epsilon}
\end{equation}

The third possible case of spurious edges $(u,v)$ are those for which $u=i$ but $v \neq j$. The probability that any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{h}$. Let $Z_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Z_k] = \frac{B_p(i)}{h}$. By Markov's inequality,

\begin{equation} \label{efreq3}
P(Z_k \geq h B_p(i) \cdot \epsilon) \leq \frac{E[Z_k]}{h B_p(i) \cdot \epsilon} = \frac{1}{h^2\epsilon}
\end{equation}

Combining inequations \ref{efreq1}, \ref{efreq2}, \ref{efreq3},
\begin{equation} \label{efreq4}
  P(X_k + Y_k + Z_k \geq L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon) \leq \frac{2^{d+1}+1}{h^2\cdot\epsilon}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(\overline{Q(i,j)} \leq Q(i,j) + L_p \cdot \epsilon + A_p(i) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon)
\\  &= 1 - \prod _{k=1}^{w}P(X_k + Y_k + Z_k \geq L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon)
\\  &\geq 1-(\frac{2^{d+1}+1}{h^2\cdot\epsilon})^w
\end{split}
\end{align}

\end{proof}

\begin{remarks}
  The probability of the guarantee gets lower as the depth $d$ of the recursion in which a partition is built gets deeper, but in ideal partitioning, the guarantee of the estimate of the partition itself gets better as $L_p$, $A_p(i)$, and $B_p(i)$ are reduced.
\end{remarks}


\section{Heavy-hitter Edge Queries}
\subsubsection{Description}
Obtaining edges with frequencies at least $F$ in the graph stream is accomplished by first obtaining a set of edges with frequencies at least $F$ from each partition in the gMatrix and then taking the union of each of them.

\subsubsection{Analysis}

\begin{theorem}
Let $(i,j)$ be an edge and $p$ be the partition associated with $i$. Let $Q(i,j)$ be its actual frequency, and $\overline{Q(i,j)}$ be its estimated frequency according to partition $p$. Let $L_p$ be the total frequency of edges received so far in the arbitrary partition, i.e. total frequency of edges $(u,v)$ such that $u$ is associated with $p$. Let $A_p(j)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $v=j$. Let $B_p(i)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $u=i$. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
\[
P(Q(i,j) \geq F) \geq 1-(\frac{3\cdot2^d(L_p+h\cdot A_p(j)) + 3\cdot h\cdot B_p(i)}{h^2\cdot (\overline{Q(i,j)}-F)})^w
\]
\end{theorem}

\begin{proof}
Note that if the number of spurious edges is at most $(\overline{Q(i,j)} - F)$, the true frequency $Q(i,j)$ is at least $F$, so by obtaining a lower bound for the probability of the former, we obtain a lower bound for the probability of the latter as well.

To obtain a lower bound for the probability that the number of spurious edges is at most $(\overline{Q(i,j)} - F)$, we consider all possible cases of spurious edges.

The first possible case of spurious edges $(u,v)$ are those for which $u \neq i$ and $v \neq j$. Any of such edges are equally likely to be mapped into any cell in $p$, and the probability to be mapped into any particular cell is $\frac{1}{h \cdot \frac{h}{2^d}} = \frac{2^d}{h^2}$. Let $X_k$ be a random variable that represents the number of such spurious edges that are mapped into $(g_k(i),g_k(j),k)$. Therefore, $E[X_k] = \frac{2^dL_p}{h^2}$. Then, by Markov's inequality,

\begin{equation} \label{hh1}
P(X_k \geq \frac{\overline{Q(i,j)}-F}{3}) \leq \frac{E[X_k]}{\frac{\overline{Q(i,j)}-F}{3}} = \frac{3\cdot2^dL_p}{h^2(\overline{Q(i,j)}-F)}
\end{equation}

The second possible case of spurious edges $(u,v)$ are those for which $u \neq i$ but $v=j$. The probability that any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{\frac{h}{2^d}} = \frac{2^d}{h}$. Let $Y_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Y_k] = \frac{2^dA_p(j)}{h}$. By Markov's inequality,

\begin{equation} \label{hh2}
P(Y_k \geq \frac{\overline{Q(i,j)}-F}{3}) \leq \frac{E[Y_k]}{\frac{\overline{Q(i,j)}-F}{3}} = \frac{3\cdot2^dA_p(j)}{h(\overline{Q(i,j)}-F)}
\end{equation}

The third possible case of spurious edges $(u,v)$ are those for which $u=i$ but $v \neq j$. The probability that any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{h}$. Let $Z_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Z_k] = \frac{B_p(i)}{h}$. By Markov's inequality,

\begin{equation} \label{hh3}
P(Z_k \geq \frac{\overline{Q(i,j)}-F}{3}) \leq \frac{E[Z_k]}{\frac{\overline{Q(i,j)}-F}{3}} = \frac{3\cdot B_p(i)}{h(\overline{Q(i,j)}-F)}
\end{equation}

Combining inequations \ref{hh1}, \ref{hh2}, \ref{hh3},
\begin{equation}
  P(X_k + Y_k + Z_k \geq \overline{Q(i,j)}-F) \leq \frac{3\cdot2^d(L_p+h\cdot A_p(j)) + 3\cdot h\cdot B_p(i)}{h^2\cdot (\overline{Q(i,j)}-F)}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(Q(i,j) \geq F)
\\  &= 1 - \prod _{k=1}^{w}P(X_k + Y_k + Z_k \geq \overline{Q(i,j)}-F)
\\  &\geq 1-(\frac{3\cdot2^d(L_p+h\cdot A_p(j)) + 3\cdot h\cdot B_p(i)}{h^2\cdot (\overline{Q(i,j)}-F)})^w
\end{split}
\end{align}

\end{proof}

\section{Node Aggregate-Frequency Queries}

The queries ask for the sum of frequencies of all edges incoming to / outgoing from a node $i$. Due to partitioning based on source nodes, source-node aggregate-frequency queries and destination-node aggregate-frequency queries are computed differently.

\subsection{Source-Node Aggregate-Frequency Queries}

\subsubsection{Description}
The task of finding the aggregate frequency of a source node $i$ is broken down to:

\begin{enumerate}
\item Finding the associated partition $p$ of $i$
\item Finding the aggregate frequency of the source node $i$ at the partition $p$
\end{enumerate}

\subsubsection{Analysis}

\begin{theorem}
Let $(i,j)$ be an edge and $p$ be the partition associated with $i$. Let $Q_{agg}^{+}(i)$ be the true aggregate-frequency of source-node $i$, and $\overline{Q_{agg}^{+}(i)}$ be its estimated aggregate-frequency. Let $p$ be a partition associated with $i$ and $L_p$ be the total frequency of edges received so far on $p$. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
\[
P(Q_{agg}^{+}(i) \leq \overline{Q_{agg}^{+}(i)} \leq Q_{agg}^{+}(i) + L_p \cdot \epsilon) \geq 1-(\frac{2^d}{h\cdot\epsilon})^w
\]
\end{theorem}

\begin{proof}
We note that $P(Q_{agg}^{+}(i) \leq \overline{Q_{agg}^{+}(i)}) = 1$ since $\overline{Q_{agg}^{+}(i)}$ is always an overestimate. We remain to show that
\[
P(\overline{Q_{agg}^{+}(i)} \leq Q_{agg}^{+}(i) + L_p \cdot \epsilon) \geq 1-(\frac{2^d}{h\cdot\epsilon})^w
\]
In any arbitrary partition $p$, the probability for a spurious edge $(u,v)$, where $u \neq i$ and $u$ is associated with $p$, to be mapped onto $(g_k(i),\cdot,k)$ is $\frac{1}{\frac{h}{2^d}} = \frac{2^d}{h}$, so the expected number of spurious edges that are mapped into $(g_k(i),\cdot,k)$ is $\frac{2^dL_p}{h}$. Let $R_k$ be the random variable that represents the number of such spurious edges for the $k^{th}$ hash function. By Markov's inequality,

\begin{equation} \label{agg21}
  P(R_k \geq L_p \epsilon) \leq \frac{E[R_k]}{L_p \epsilon} = \frac{2^d}{h\epsilon}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(\overline{Q_{agg}^{+}(i)} \leq Q_{agg}^{+}(i) + L_p \cdot \epsilon)
\\  &= 1 - \prod _{k=1}^{w}P(R_k \geq L_p \cdot \epsilon)
\\  &\geq 1-(\frac{2^d}{h\cdot\epsilon})^w
\end{split}
\end{align}

\end{proof}

\begin{remarks}
As the depth $d$ of the recursion in which the partition is built increases, the probability of the accuracy guarantee decreases, but in ideal partitioning, the accuracy guarantee itself gets better as $L_p$ gets reduced.
\end{remarks}

\subsection{Destination-Node Aggregate-Frequency Queries}

\subsubsection{Description}
The task of finding the aggregate-frequency of a destination node $j$ is broken down to:

\begin{enumerate}
\item Computing the aggregate-frequency of the destination-node $j$ in each partition $p$
\item Computing the sum of all of the computed destination-node aggregate-frequencies together
\end{enumerate}

\subsubsection{Analysis}
\begin{theorem}
\label{agg2}
  Let $Q_{agg}^{-}(j)$ be the true aggregate-frequency of destination-node $j$, and $\overline{Q_{agg}^{-}(j)}$ be the estimated aggregate-frequency. Let $L$ be the total frequency of edges received so far. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
  
  \[
P(Q_{agg}^{-}(j) \leq \overline{Q_{agg}^{-}(j)} \leq Q_{agg}^{-}(j) + L \cdot \epsilon) \geq 1-(\frac{n}{h\cdot\epsilon})^w
\]

\end{theorem}

\begin{proof}
We note that $P(Q_{agg}^{-}(j) \leq \overline{Q_{agg}^{-}(j)}) = 1$ since $\overline{Q_{agg}^{-}(j)}$ is always an overestimate. We remain to show that
\[
P(\overline{Q_{agg}^{-}(j)} \leq Q_{agg}^{-}(j) + L \cdot \epsilon) \geq 1-(\frac{n}{h\cdot\epsilon})^w
\]
Let $\{p_1,..,p_n\}$ be the set of all partitions in the gMatrix and $L_i$ be the total frequency of edges in $p_i$. In any partition $p_i$, the probability for a spurious edge $(u,v)$, $v \neq j$ to be mapped onto $(\cdot,g_k(j),k)$ is $\frac{1}{h}$, so the expected number of spurious edges that are mapped into $(\cdot,g_k(j),k)$ is $\frac{L_i}{h}$. Let $R_k^i$ be the random variable that represents the number of spurious edges in $p_i$ for the $k^{th}$ hash function. By Markov's inequality,

\begin{equation} \label{agg21}
  P(R_k^i \geq L_i \epsilon) \leq \frac{E[R_k^i]}{L_i \epsilon} = \frac{1}{h\epsilon}
\end{equation}

Let $R_k = \sum_{i=1}^{n} R_k^i$. Combining inequation \ref{agg21} for all $i \in \{1..n\}$, 

\begin{equation} \label{agg22}
 P(R_k \geq L\epsilon) \leq \frac{n}{h\epsilon}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(\overline{Q_{agg}^{-}(j)} \leq Q_{agg}^{-}(j) + L \cdot \epsilon)
\\  &= 1 - \prod _{k=1}^{w}P(R_k \geq L \cdot \epsilon)
\\  &\geq 1-(\frac{n}{h\cdot\epsilon})^w
\end{split}
\end{align}

\end{proof}

\begin{remarks}
The probability of the guarantee gets lower as the number of partitions increases, and the guarantee itself never gets any better with partitioning.
\end{remarks}
