%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Design and Analysis}

\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi


\section{Preliminaries}

\subsection{Count-Min Sketch}
The Count-Min \cite{cormode2005improved} sketch is a data-stream sketch that is used to approximate frequency counts of items in a data stream.

It consists of a 2D array. In a $h \times w$ sized Count-Min sketch, it consists of $w$ many hash functions that each maps onto $[0,h-1]$.

To store the frequency of an item $x$, it first maps $x$ onto $w$ different values $g_k(x) \in [0,h-1]$ using each hash function $g_k, k \in \{1..w\}$. Then, the entry at the $g_k(x)^{th}$ row, $k^{th}$ column is incremented by the frequency of $x$.

Let the entry of the sketch at the $i^{th}$ row, $j^{th}$ column be denoted by $f(i,j)$. Querying the frequency estimate of an item $x$ is accomplished by finding $min\{f(g_k(x),k)|k \in \{1..w\}\}$.

\subsection{gMatrix Sketch}
The gMatrix \cite{khan} is a sketch that is similar to the Count-Min sketch, except that it consists of a 3D array instead of a 2D one and specializes on graph streams.

In a $h \times h \times w$ sized gMatrix, to store the frequency of an edge $(i,j)$, it first maps $i$ and $j$ onto $w$ different values $g_k(i)$ and $g_k(j)$ using each hash function $g_k, k \in \{1..w\}$. Then, the entry at the $g_k(i)^{th}$ row, $g_k(j)^{th}$ column, and $k^{th}$ layer is incremented by the frequency of the edge $(i,j)$.

Let the entry of the sketch at the $i^{th}$ row, $j^{th}$ column, and $k^{th}$ layer be denoted by $f(i,j,k)$. Querying the frequency estimate of an edge $(i,j)$ is accomplished by finding $min\{f(g_k(i),g_k(j),k)|k \in \{1..w\}\}$.

\subsection{gSketch Partitioning Method}
\begin{algorithm}
\caption{Sketch-Partitioning-On-CountMin \cite{DBLP} (Data Sample: $D$)}\label{cm}
\begin{algorithmic}[1]

\State Create a root node $S$ of the partitioning tree as an
active node;
\State $S.width \gets h$;
\State $S.depth \gets w$;
\State Create an empty list $L$ containing $S$ only;
\While{$L \neq \varnothing$ }
\State Partition active node $S \in L$ based on D into $S_1$, $S_2$ by minimizing E in equation \ref{objective};
\State $S_1.width = S_2.width = \frac{S.width}{2};$
\State $L \gets L \setminus \{ S \};$
\If{$(S_1.width \geq w_0)$ and ($\sum_{m \in S_1} \tilde{d}(m) > C \cdot S_1.width$)}
\State $L \gets L \cup S_1$;
\Else
\State Construct the localized sketch $S_1$;
\EndIf

\If{$(S_2.width \geq w_0)$ and ($\sum_{m \in S_2} \tilde{d}(m) > C \cdot S_2.width$)}
\State $L \gets L \cup S_2$;
\Else
\State Construct the localized sketch $S_2$;
\EndIf

\EndWhile

\end{algorithmic}
\end{algorithm}
The gSketch \cite{DBLP} is a partitioning method performed onto a graph-stream sketch prior to being populated with the stream. The partitioning method is based on the source vertex set of a sample stream. The method, as shown in Algorithm \ref{cm} \cite{DBLP}, is recursive and on each step of the recursion, it first sorts the sample in order of non-decreasing average edge frequency, which is estimated by the ratio of vertex aggregate-frequency to its degree $\frac{\tilde{f_v(m)}}{\tilde{d(m)}}$, and then selects a pivot on which the sorted list is to be partitioned into two by minimizing an objective function,
\begin{equation}
\label{objective}
E = \sum_{m \in S_1} \frac{\tilde{d}(m) \cdot \tilde{F}(S_1)}{\tilde{f}_v(m) / \tilde{d}(m)} + \sum_{m \in S_2} \frac{\tilde{d}(m) \cdot \tilde{F}(S_2)}{\tilde{f}_v(m) / \tilde{d}(m)}
\end{equation}, where $S_1$ and $S_2$ are the two produced partitions based on the selected pivot on the step of the recursion and $\tilde{F}(S_i)$ is its total frequency, and that when minimized, the overall relative error of the whole sketch is minimized as well.

As shown in Algorithm \ref{cm}, there are two conditions in which if any one of the two is met, the recursion is immediately terminated and starts to build the local partition $S$:

\begin{enumerate}
\item $S.width < w_0$ as the sketch is small enough.
\item $\sum_{m\in S}\tilde{d}(m) \leq C \cdot S.width$, where $C$ is a constant, as it implies that the probability for any collisions to occur in any cell of $S$ can be bounded above by $C$.
\end{enumerate}


\section{gSketch Partitioning Method for gMatrix}

The gSketch partitioning\cite{DBLP} is shown to improve Count-Min's\cite{cormode2005improved} accuracy. The partitioning works by grouping edges with similar frequencies in the same partition to improve sketch accuracy and requires an available data sample.

The same partitioning method can also be applied onto the gMatrix, as shown in Algorithm \ref{gmat}, by changing the width $S.width$ of the Count-Min sketch with the number of rows of the gMatrix $S.rows$.

\begin{algorithm}
\caption{Sketch-Partitioning-On-gMatrix (Data Sample: $D$)}\label{gmat}
\begin{algorithmic}[1]

\State Create a root node $S$ of the partitioning tree as an
active node;
\State $S.rows \gets h$;
\State $S.cols \gets h$;
\State $S.depth \gets w$;
\State Create an empty list $L$ containing $S$ only;
\While{$L \neq \varnothing$ }
\State Partition active node $S \in L$ based on D into $S_1$, $S_2$ by minimizing E in equation \ref{objective};
\State $S_1.rows = S_2.rows = \frac{S.rows}{2};$
\State $L \gets L \setminus \{ S \};$
\If{$(S_1.rows \geq w_0)$ and ($\sum_{m \in S_1} \tilde{d}(m) > C \cdot S_1.rows$)}
\State $L \gets L \cup S_1$;
\Else
\State Construct the localized sketch $S_1$;
\EndIf

\If{$(S_2.rows \geq w_0)$ and ($\sum_{m \in S_2} \tilde{d}(m) > C \cdot S_2.rows$)}
\State $L \gets L \cup S_2$;
\Else
\State Construct the localized sketch $S_2$;
\EndIf

\EndWhile

\end{algorithmic}
\end{algorithm}

We provide a proof that the terminating condition $\sum_{m \in S} \tilde{d}(m) \leq C \cdot S.rows$ still guarantees that the probability for any collisions to occur in the sketch partition is bounded above by $C$.

\begin{theorem}
Let $S$ be a gMatrix partition and $0<C<1$ be a constant. Then, the condition $\sum_{m \in S} \tilde{d}(m) \leq C \cdot S.rows$ implies that the probability for any collisions to occur in $S$ is bounded above by C.
\end{theorem}

\begin{proof}
There are two cases of spurious edges that may collide with an edge $(i,j)$ in $S$. The first case of such edges are those for which both end-points are neither $i$ nor $j$, and the probability of collision is $\frac{1}{S.rows \cdot S.cols}$. The second case of such edges are those for which either the source node is $i$ too or the destination node is $j$ too, and the probability of collision is $\frac{1}{S.cols}$ and $\frac{1}{S.rows}$ consecutively. Since the partitioning divides the number of rows into half on each step of the recursion, on an $h \times h \times w$ gMatrix, it always holds that $S.rows \leq S.cols$, and so the probability of collision is at most $\frac{1}{S.rows}$. Since there are $\sum_{m \in S} \tilde{d}(m)$ distinct edges in $S$, the probability for any collisions to occur is at most $\frac{\sum_{m \in S} \tilde{d}(m)}{S.rows}$. Therefore, $\sum_{m \in S} \tilde{d}(m) \leq C \cdot S.rows$ guarantees that the probability for any collisions to occur in the sketch is bounded above by $C$.
\end{proof}

After partitioning, each of the resulting partitions is associated with a set of source vertices. Each source vertex is then only associated with exactly one partition. Edge $(u,v)$ is stored in partition $p$ if and only if $u$ is in the set of source vertices associated with the partition $p$. An outlier partition is then needed to be reserved to store frequencies of edges in the dataset whose source node is not associated with any of the resulting partitions of the sketch partitioning algorithm.

We propose two new optimizations to the partitioning method. The first is that since the partitioning works by grouping edges with similar average frequencies together estimated by the ratio of source-vertex aggregate-frequency to its degree $\frac{\tilde{f}_v(m)}{\tilde{d}(m)}$ and that edges with a common source-node $m$ are assumed to have similar frequencies, we can filter ones for which the assumption does not hold. In particular, we can compute the statistical variances of the frequencies of edges from the data sample with common source nodes and filter edges with source nodes for which the variance of the frequencies is exceeding a certain threshold.

Another observation is that the outlier partition size to be used for the sketch can be estimated by computing the outlier ratio from the data sample. We do so by first splitting the data sample into two, and then after selecting the suitable source nodes from the first split, the ratio of outliers in the second split is computed, which is essentially the ratio of the number of source nodes in the split not found among the previously-selected source nodes to the size of the split.

Next, we observe how gMatrix answers various query types after being partitioned and how partitioning affects gMatrix's accuracy.

\subsection{Edge Frequency Query Estimation}

Since there is only one partition associated with each source vertex, to retrieve the estimated frequency for an arbitrary edge $(i,j)$:

\begin{enumerate}
  \item Find partition $p$ that is responsible for $i$
  \item Find $min\{V_P(g_k(i),g_k(j),k)|\forall k \in \{1..w\}\}$, where $V_P$ is the value of the cell in the partition $p$. 
\end{enumerate}

The number of operations taken by the first step depends on implementation. If a hash-table that maps each source-vertex onto its allocated partition is to be built during the sketch partitioning algorithm, the first step takes $\mathcal{O}(1)$ operations in average. For worst-case time complexity analysis, if a balanced binary search tree is to be used instead of the hash-table, the first step takes $\mathcal{O}(lg(|V^{+}|))$ operations, where $V^{+}$ is the set of source verticesnodes from the data sample.

The second step takes $\mathcal{O}(w)$ operations.

Thus, the worst-case time complexity is $\mathcal{O}(lg(|V^{+}|) + w)$.

Since obtaining the frequency estimate of an arbitrary edge only depends on the partition containing the edge, we observe how each partition answers the query.

Let $S$ be a gMatrix of size $h\times h\times w$. Suppose the partitioning step has been performed already. Note that any of the produced partitions will have number of rows equal to $\frac{h}{2^d}$ where $d$ is the depth of the recursion in which the partition is built. Let $p$ be an arbitrary partition. The size of $p$ is $\frac{h}{2^d}\times h\times w$.

\begin{theorem}
\label{thm:efreqguarantee}
Let $p$ be a partition built at depth $d$ of the sketch partitioning algorithm. Let $(i,j)$ be an edge in $p$, $Q(i,j)$ be its actual frequency, and $\overline{Q(i,j)}$ be its estimated frequency according to partition $p$. Let $L_p$ be the total frequency of edges received so far in the arbitrary partition, i.e. total frequency of edges $(u,v)$ such that $u$ is associated with $p$. Let $A_p(j)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $v=j$. Let $B_p(i)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $u=i$. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
  
  \[
P(Q(i,j) \leq \overline{Q(i,j)} \leq Q(i,j) + L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon) \geq 1-(\frac{2^{d+1}+1}{h^2\cdot\epsilon})^w
\]

\end{theorem}

\begin{proof}
  Note that $\overline{Q(i,j)}$ is essentially $Q(i,j)$ added with the frequencies of spurious edges mapped into the same cell $(g_k(i),g_k(j),k)$ in the partition, so $P(Q(i,j) \leq \overline{Q(i,j)}) = 1$. We remain to show that

\[
P(\overline{Q(i,j)} \leq Q(i,j) + L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon) \geq 1-(\frac{2^{d+1}+1}{h^2\cdot\epsilon})^w
\]

  There are three possible cases for the spurious edges.
  
The first possible case of spurious edges $(u,v)$ are those for which $u \neq i$ and $v \neq j$. Any of such edges are equally likely to be mapped into any cell in $p$, and the probability to be mapped into any particular cell is $\frac{1}{h \cdot \frac{h}{2^d}} = \frac{2^d}{h^2}$. Let $X_k$ be a random variable that represents the number of such spurious edges that are mapped into $(g_k(i),g_k(j),k)$. Therefore, $E[X_k] = \frac{2^dL_p}{h^2}$. Then, by Markov's inequality,

\begin{equation} \label{efreq1}
P(X_k \geq L_p \cdot \epsilon) \leq \frac{E[X_k]}{L_p \cdot \epsilon} = \frac{2^d}{h^2\epsilon}
\end{equation}

The second possible case of spurious edges $(u,v)$ are those for which $u \neq i$ but $v=j$. The probability for any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{\frac{h}{2^d}} = \frac{2^d}{h}$. Let $Y_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Y_k] = \frac{2^dA_p(j)}{h}$. By Markov's inequality,

\begin{equation} \label{efreq2}
P(Y_k \geq h A_p(j) \cdot \epsilon) \leq \frac{E[Y_k]}{h A_p(j) \cdot \epsilon} = \frac{2^d}{h^2\epsilon}
\end{equation}

The third possible case of spurious edges $(u,v)$ are those for which $u=i$ but $v \neq j$. The probability for any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{h}$. Let $Z_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Z_k] = \frac{B_p(i)}{h}$. By Markov's inequality,

\begin{equation} \label{efreq3}
P(Z_k \geq h B_p(i) \cdot \epsilon) \leq \frac{E[Z_k]}{h B_p(i) \cdot \epsilon} = \frac{1}{h^2\epsilon}
\end{equation}

Combining inequations \ref{efreq1}, \ref{efreq2}, \ref{efreq3},
\begin{equation} \label{efreq4}
  P(X_k + Y_k + Z_k \geq L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon) \leq \frac{2^{d+1}+1}{h^2\cdot\epsilon}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(\overline{Q(i,j)} \leq Q(i,j) + L_p \cdot \epsilon + A_p(i) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon)
\\  &= 1 - \prod _{k=1}^{w}P(X_k + Y_k + Z_k \geq L_p \cdot \epsilon + A_p(j) \cdot h \cdot \epsilon + B_p(i) \cdot h \cdot \epsilon)
\\  &\geq 1-(\frac{2^{d+1}+1}{h^2\cdot\epsilon})^w
\end{split}
\end{align}

\end{proof}

\begin{remarks}
  The probability of the guarantee gets lower as the depth $d$ of the recursion in which a partition is built gets deeper, but in ideal partitioning, the guarantee of the estimate of the partition itself gets better as $L_p$, $A_p(i)$, and $B_p(i)$ are reduced.
\end{remarks}


\subsection{Heavy-hitter Edge Query Estimation}
The query asks for retrieving the set of edges in the graph stream with frequencies at least $F$. The query is accomplished by the following steps:

\begin{enumerate}
\item obtain the set of edges with frequencies at least $F$ from each partition in the gMatrix, which can be accomplished as described in \cite{khan}
\item compute the union of each of the obtained sets.
\end{enumerate}

Without partitioning, we only need to perform step 1 once, but with partitioning, we need to perform it $n$ times, where $n$ is the number of partitions, so it is already at least $n$ times slower than without partitioning in the worst case. Thus, the first step takes $\mathcal{O}(nh^2w + 2 n \left \lfloor{P/h} \right \rfloor log P \prod_{k=1}^wc_k)$ operations \cite{khan}, where $c_k$ is the number of cells in the $k^{th}$ layer whose entries are at least $F$, and $P$ is a gMatrix parameter for generating hash functions and is a prime number larger than the maximum number of nodes in the graph stream.

For the second step, if the partitioning algorithm produces only one partition, there are no union operations performed. Otherwise, the second step takes $\Omega(|H|)$ operations, where $H$ denotes the set of true heavy-hitter edges in the graph stream.

As in \cite{khan}, the resulting set of heavy-hitter edges may consist of edges that are not actually heavy-hitter edges, but the set of all true heavy-hitter edges is always a subset, i.e. there are no missing true heavy-hitter edges in the resulting set.

We observe the probability that an edge $(i,j)$ is correctly classified as a heavy-hitter edge in each partition.

\begin{theorem}
Let $p$ be a partition built at depth $d$ of the sketch partitioning algorithm. Let $(i,j)$ be an edge in $p$. Let $Q(i,j)$ be its actual frequency, and $\overline{Q(i,j)}$ be its estimated frequency according to partition $p$. Let $L_p$ be the total frequency of edges received so far in the arbitrary partition, i.e. total frequency of edges $(u,v)$ such that $u$ is associated with $p$. Let $A_p(j)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $v=j$. Let $B_p(i)$ be the sum of the frequencies of edges $(u,v)$ on $p$ such that $u=i$. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
\[
P(Q(i,j) \geq F) \geq 1-(\frac{3\cdot2^d(L_p+h\cdot A_p(j)) + 3\cdot h\cdot B_p(i)}{h^2\cdot (\overline{Q(i,j)}-F)})^w
\]
\end{theorem}

\begin{proof}
Note that if the number of spurious edges is at most $(\overline{Q(i,j)} - F)$, the true frequency $Q(i,j)$ is at least $F$, so by obtaining a lower bound for the probability of the former, we obtain a lower bound for the probability of the latter as well.

To obtain a lower bound for the probability that the number of spurious edges is at most $(\overline{Q(i,j)} - F)$, we consider all possible cases of spurious edges.

The first possible case of spurious edges $(u,v)$ are those for which $u \neq i$ and $v \neq j$. Any of such edges are equally likely to be mapped into any cell in $p$, and the probability to be mapped into any particular cell is $\frac{1}{h \cdot \frac{h}{2^d}} = \frac{2^d}{h^2}$. Let $X_k$ be a random variable that represents the number of such spurious edges that are mapped into $(g_k(i),g_k(j),k)$. Therefore, $E[X_k] = \frac{2^dL_p}{h^2}$. Then, by Markov's inequality,

\begin{equation} \label{hh1}
P(X_k \geq \frac{\overline{Q(i,j)}-F}{3}) \leq \frac{E[X_k]}{\frac{\overline{Q(i,j)}-F}{3}} = \frac{3\cdot2^dL_p}{h^2(\overline{Q(i,j)}-F)}
\end{equation}

The second possible case of spurious edges $(u,v)$ are those for which $u \neq i$ but $v=j$. The probability for any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{\frac{h}{2^d}} = \frac{2^d}{h}$. Let $Y_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Y_k] = \frac{2^dA_p(j)}{h}$. By Markov's inequality,

\begin{equation} \label{hh2}
P(Y_k \geq \frac{\overline{Q(i,j)}-F}{3}) \leq \frac{E[Y_k]}{\frac{\overline{Q(i,j)}-F}{3}} = \frac{3\cdot2^dA_p(j)}{h(\overline{Q(i,j)}-F)}
\end{equation}

The third possible case of spurious edges $(u,v)$ are those for which $u=i$ but $v \neq j$. The probability for any of such edges to be mapped into $(g_k(i),g_k(j),k)$ in $p$ is $\frac{1}{h}$. Let $Z_k$ be a random variable representing the number of such spurious edges. Therefore, $E[Z_k] = \frac{B_p(i)}{h}$. By Markov's inequality,

\begin{equation} \label{hh3}
P(Z_k \geq \frac{\overline{Q(i,j)}-F}{3}) \leq \frac{E[Z_k]}{\frac{\overline{Q(i,j)}-F}{3}} = \frac{3\cdot B_p(i)}{h(\overline{Q(i,j)}-F)}
\end{equation}

Combining inequations \ref{hh1}, \ref{hh2}, \ref{hh3},
\begin{equation}
  P(X_k + Y_k + Z_k \geq \overline{Q(i,j)}-F) \leq \frac{3\cdot2^d(L_p+h\cdot A_p(j)) + 3\cdot h\cdot B_p(i)}{h^2\cdot (\overline{Q(i,j)}-F)}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(Q(i,j) \geq F)
\\  &= 1 - \prod _{k=1}^{w}P(X_k + Y_k + Z_k \geq \overline{Q(i,j)}-F)
\\  &\geq 1-(\frac{3\cdot2^d(L_p+h\cdot A_p(j)) + 3\cdot h\cdot B_p(i)}{h^2\cdot (\overline{Q(i,j)}-F)})^w
\end{split}
\end{align}

\end{proof}

\subsection{Node Aggregate-Frequency Query Estimation}

The queries ask for the sum of frequencies of all edges incoming to / outgoing from a node $i$. Due to partitioning based on source nodes, source-node aggregate-frequency queries and destination-node aggregate-frequency queries are answered differently.

\subsubsection{Source-Node Aggregate-Frequency Query Estimation}

The task of finding the aggregate frequency of a source node $i$ is broken down to the following steps:

\begin{enumerate}
\item Finding the associated partition $p$ of $i$.
\item Finding the aggregate frequency of the source node $i$ at the partition $p$, which can be accomplished as described in \cite{khan}.
\end{enumerate}

The number of operations taken by the first step depends on implementation. If a hash-table that maps each source-vertex onto its allocated partition is to be built during the sketch partitioning algorithm, the first step takes $\mathcal{O}(1)$ operations in average. For worst-case time complexity analysis, if a balanced binary search tree is to be used instead of the hash-table, the first step takes $\mathcal{O}(lg(|V^{+}|))$ operations, where $V^{+}$ is the set of source verticesnodes from the data sample.

The second one takes $\mathcal{O}(hw)$ operations, so the query can be answered in $\mathcal{O}(hw)$ operations.

Thus, the overall time complexity is $\mathcal{O}(lg(|V^{+}|) + hw)$.

Next, we observe how partitioning affects the probabilistic accuracy guarantee.

\begin{theorem}
\label{thm:agg1}
Let $p$ be a partition built at depth $d$ of the sketch partitioning algorithm. Let $(i,j)$ be an edge in $p$. Let $Q_{agg}^{+}(i)$ be the true aggregate-frequency of source-node $i$, and $\overline{Q_{agg}^{+}(i)}$ be its estimated aggregate-frequency. Let $L_p$ be the total frequency of edges received so far on $p$. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
\[
P(Q_{agg}^{+}(i) \leq \overline{Q_{agg}^{+}(i)} \leq Q_{agg}^{+}(i) + L_p \cdot \epsilon) \geq 1-(\frac{2^d}{h\cdot\epsilon})^w
\]
\end{theorem}

\begin{proof}
We note that $P(Q_{agg}^{+}(i) \leq \overline{Q_{agg}^{+}(i)}) = 1$ since $\overline{Q_{agg}^{+}(i)}$ is always an overestimate. We remain to show that
\[
P(\overline{Q_{agg}^{+}(i)} \leq Q_{agg}^{+}(i) + L_p \cdot \epsilon) \geq 1-(\frac{2^d}{h\cdot\epsilon})^w
\]
In any arbitrary partition $p$, the probability for a spurious edge $(u,v)$, where $u \neq i$ and $u$ is associated with $p$, to be mapped onto any of the columns at the $g_k(i)^{th}$ row, $k^{th}$ layer of $p$ is $\frac{1}{\frac{h}{2^d}} = \frac{2^d}{h}$, so the expected number of spurious edges is $\frac{2^dL_p}{h}$. Let $R_k$ be the random variable that represents the number of such spurious edges for the $k^{th}$ hash function. By Markov's inequality,

\begin{equation} \label{agg21}
  P(R_k \geq L_p \epsilon) \leq \frac{E[R_k]}{L_p \epsilon} = \frac{2^d}{h\epsilon}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(\overline{Q_{agg}^{+}(i)} \leq Q_{agg}^{+}(i) + L_p \cdot \epsilon)
\\  &= 1 - \prod _{k=1}^{w}P(R_k \geq L_p \cdot \epsilon)
\\  &\geq 1-(\frac{2^d}{h\cdot\epsilon})^w
\end{split}
\end{align}

\end{proof}

\begin{remarks}
As the depth $d$ of the recursion in which the partition is built increases, the probability of the accuracy guarantee decreases, but in ideal partitioning, the accuracy guarantee itself gets better as $L_p$ gets reduced.
\end{remarks}

\subsubsection{Destination-Node Aggregate-Frequency Query Estimation}

The task of finding the aggregate-frequency of a destination node $j$ is broken down to:

\begin{enumerate}
\item Computing the aggregate-frequency of the destination-node $j$ in each partition $p$, which can be accomplished as described in \cite{khan}.
\item Computing the sum of all of the computed destination-node aggregate-frequencies together
\end{enumerate}

The first step implies that the time complexity for answering the query is at least $n$ times slower in the worst case than it is without partitioning, where $n$ is the number of partitions after performing the sketch partitioning algorithm. The second step only takes $\mathcal{O}(n)$ operations. Thus, the worst-case time complexity to answer the query is $\mathcal{O}(nhw)$.

Next, we observe how partitioning affects the probabilistic accuracy guarantee.
\begin{theorem}
\label{thm:agg2}
Let $Q_{agg}^{-}(j)$ be the true aggregate-frequency of destination-node $j$, and $\overline{Q_{agg}^{-}(j)}$ be the estimated aggregate-frequency. Let $L$ be the total frequency of edges received so far. Let $\epsilon \in (0,1)$ be a very small fraction. Then,
  
  \[
P(Q_{agg}^{-}(j) \leq \overline{Q_{agg}^{-}(j)} \leq Q_{agg}^{-}(j) + L \cdot \epsilon) \geq 1-(\frac{n}{h\cdot\epsilon})^w
\]

\end{theorem}

\begin{proof}
We note that $P(Q_{agg}^{-}(j) \leq \overline{Q_{agg}^{-}(j)}) = 1$ since $\overline{Q_{agg}^{-}(j)}$ is always an overestimate. We remain to show that
\[
P(\overline{Q_{agg}^{-}(j)} \leq Q_{agg}^{-}(j) + L \cdot \epsilon) \geq 1-(\frac{n}{h\cdot\epsilon})^w
\]
Let $\{p_1,..,p_n\}$ be the set of all partitions in the gMatrix and $L_i$ be the total frequency of edges in $p_i$. In any partition $p_i$, the probability for a spurious edge $(u,v)$, $v \neq j$ to be mapped onto any of the rows at the $g_k(j)^{th}$ column, $k^{th}$ layer is $\frac{1}{h}$, so the expected number of spurious edges is $\frac{L_i}{h}$. Let $R_k^i$ be the random variable that represents the number of spurious edges in $p_i$ for the $k^{th}$ hash function. By Markov's inequality,

\begin{equation} \label{agg21}
  P(R_k^i \geq L_i \epsilon) \leq \frac{E[R_k^i]}{L_i \epsilon} = \frac{1}{h\epsilon}
\end{equation}

Let $R_k = \sum_{i=1}^{n} R_k^i$ be the total number of spurious edges in all of the $n$ partitions. Combining inequation \ref{agg21} for all $i \in \{1..n\}$, 

\begin{equation} \label{agg22}
 P(R_k \geq L\epsilon) \leq \frac{n}{h\epsilon}
\end{equation}

Therefore,
\begin{align}
\begin{split}
&  P(\overline{Q_{agg}^{-}(j)} \leq Q_{agg}^{-}(j) + L \cdot \epsilon)
\\  &= 1 - \prod _{k=1}^{w}P(R_k \geq L \cdot \epsilon)
\\  &\geq 1-(\frac{n}{h\cdot\epsilon})^w
\end{split}
\end{align}

\end{proof}

\begin{remarks}
The probability of the guarantee gets lower as the number of partitions increases, and the guarantee itself never gets any better with partitioning. In other words, partitioning will never improve the accuracy of gMatrix for answering destination-node aggregate-frequency queries.
\end{remarks}
